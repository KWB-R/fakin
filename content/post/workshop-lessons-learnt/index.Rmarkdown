---
title: "Lessons-learnt: Auswertung der FAKIN Wissensspeicher Umfrage"
authors: 
  - rustler
  - sonnenberg
  - sprenger
  - conzelmann
  - guensch
  - jaehrig
  - kleyboecker
  - kraus
  - matzinger
  - miehe
  - kraus
  - remy
  - seis
  - stapf 
  - wicke
  - weigert
  - zamzow
date: '2019-03-13'
output:
  html_document
categories:
  - survey 
  - workshop
tags:
  - communication internal
  - workshop
  - survey
  - knowledge repo
---

Die Analyse basiert auf dem Rücklauf von insgesamt 17 Umfragebögen (davon 4 
teilweise und 13 vollständig ausgefüllt), die bis kurz vor dem Ende des 
Workshops bearbeitet wurden (*Stand: 11.03.2019 12:00*).

```{r, echo= FALSE, eval = FALSE}
remotes::install_github("cloudyr/limer")
library(limer)
library(dplyr)
library(tidyr)
library(stringr)
library(plotrix)

lime_login <- read.csv(file = "user_account.csv", stringsAsFactors = FALSE)


# Setup API details
options(lime_api = lime_login$api)
options(lime_username = lime_login$user)
options(lime_password = lime_login$pw)

get_session_key()


# Do stuff with LimeSurvey API
umfragen <- call_limer(method = "list_surveys")

fakin_index <- grep("Wissensspeicher", umfragen$surveyls_title) 

fakin_umfrage <- umfragen[fakin_index, ]


responses <- get_responses(fakin_umfrage$sid,
                           sLanguageCode = "de"
                           )  # Get results from survey


responses_workshop <- responses %>%  
  dplyr::filter(as.Date(submitdate) == "2019-03-11") 


create_marks_school <- function(x) {
  dplyr::case_when(
  x == "Sehr gut"  ~ 1,
  x == "Gut"  ~ 2,
  x == "Befriedigend"  ~ 3,
  x == "Ausreichend"  ~ 4,
  x == "Mangelhaft"  ~ 6,
  TRUE ~ 5
)
}

res_w1 <- responses_workshop %>%  
  dplyr::count(.data$W1) %>%  
  dplyr::arrange(dplyr::desc(.data$n)) %>%  
  dplyr::rename("Antwort" = "W1") %>%  
  dplyr::mutate(percent = 100*.data$n/sum(.data$n),
                mark = create_marks_school(.data$Antwort))

write.csv2(res_w1, "res_w1.csv",row.names = FALSE)


create_importance <- function(x) {
  dplyr::case_when(
    x == "Sehr wichtig"  ~ 1,
    x == "Wichtig"  ~ 2,
    x == "Unwichtig"  ~ 3,
    x == "Keine Ahnung"  ~ 5,
    TRUE ~ 4
  )
}


res_w2 <- responses_workshop %>%  
  dplyr::count(.data$W2) %>%  
  dplyr::arrange(dplyr::desc(.data$n)) %>%  
  dplyr::rename("Antwort" = "W2") %>%  
  dplyr::mutate(percent = round(100*.data$n/sum(.data$n), 1),
                order = create_importance(.data$Antwort)) %>%  
  dplyr::arrange(.data$order) %>%  
  dplyr::select(-.data$order)

write.csv2(res_w2, "res_w2.csv",row.names = FALSE)

```


# Suchspiel


```{r, echo= FALSE}
ergebnisse <- read.csv("Umfrage_642247_Der_FAKIN_Wissensspeicher_v1.0.csv",
                       stringsAsFactors = FALSE)

ergebnisse <- ergebnisse[order(ergebnisse$prozent_richtig,decreasing = TRUE),]
```

Beeindruckend an dem Suchspielergebnis (Tab. 1) ist, dass die über alle sieben 
Fragen gewichtete prozentuale korrekte Antwortwahrscheinlichkeit mit **`r round(sum(ergebnisse$prozent_richtig*ergebnisse$n/sum(ergebnisse$n)),1)` Prozent** 
unglaublich hoch ausfällt. Vor allem wenn man bedenkt, dass die meisten 
Umfrageteilnehmer die recht komplexe(n) Website(s) ([FAKIN-Wissensspeicher](https://kwb-r.gitlab.io/fakin): > 600 Seiten, [KWB Publikationsprototyp](https://kwb-r.gitlab.io/pubs): > 700 Seiten) vorher nie gesehen hatten und sie zudem unter enormen Zeitdruck standen (für die Bearbeitung waren maximal 30 Minuten 
vorgesehen).

*Tab. 1: Suchspiel-Ergebnisse (Fragen 1 - 7). Für zwei Fragen (2, 4) waren jeweils drei Antworten richtig.*
```{r, echo= FALSE, results='asis'}

sel <- ergebnisse[,c("id", "frage", "n", "prozent_richtig")]
names(sel) <- c("", "Frage", "Anzahl", "Richtig (%)")

knitr::kable(sel, row.names = FALSE)
```




*Tab. 2: Kommentare zum Suchspiel (Fragen 1 - 7)*
```{r, echo= FALSE,warning=FALSE,message=FALSE}
comments <- readr::read_csv2("statistic-survey642247_comments_v1.0.csv")

comments_f <- comments[grepl(pattern = "^F", comments$question_id), ] 

knitr::kable(comments_f)

```


# Wissensskalierung

## Bewertung FAKIN Wissensspeicher

**Frage:** Ziel des [FAKIN Wissensspeichers](../../) ist es Verknüpfungen zu den im Projekt beteiligten [Personen](../../#people), [Testprojekten](../../#projects), erstelltem [Code](../../#code), [Vorträgen (Workshops)](../../talk/), [Publikationen](../../publication/) und verwendeten [Tools](../../#tools) zu erstellen. Durch Sammlung aller Informationen an einem Ort, diesen Verknüpfungen und einer fortschrittlichen [Suchfunktion](../../tool/algolia), soll es sehr einfach sein Wissen zu finden. Wie gut ist dies deiner Meinung nach gelungen?


```{r, echo= FALSE}
w1 <- read.csv2("res_w1.csv")
w1$percent <- round(w1$percent,1)
note <- round(sum(w1$mark*w1$n/sum(w1$n)), 2) 


get_note_text <- function(note) {
  
  note_rounded <- round(note,0)
  ifelse(note_rounded == 1, 
                    "Sehr gut",
                    ifelse(note_rounded == 2, 
                    "Gut", 
                    ifelse(note_rounded == 3,
                    "Befriedigend",
                    ifelse(note_rounded == 4, 
                    "Ausreichend",
                    ifelse(note_rounded == 5,
                    "Ungenügend", 
                    "Mangelhaft")))))

}


```

Insgesamt wird der [FAKIN Wissensspeicher](../../) mit der **Schulnote `r get_note_text(note)`** (Note: `r round(note, 2)`) bewertet (Tab. 3).

*Tab. 3: Schulnoten für FAKIN Wissensspeicher* 
```{r, echo= FALSE, results='as.is'}

sel_w1 <- w1[,c("Antwort", "n", "percent")]
names(sel_w1) <- c("", "Anzahl", "Prozent")
knitr::kable(sel_w1)
```


*Tab. 4: Kommentare FAKIN Wissensspeicher*
```{r, echo= FALSE, results='as.is'}
comments_w1 <- comments[grepl(pattern = "^W1", comments$question_id), ] 

knitr::kable(comments_w1)
```

## KWB Wissensspeicher

### Bedarfsanalyse

**Frage:** Der [FAKIN Wissensspeicher](../../) ist ein Prototyp. Eine Skalierung auf das KWB ist innerhalb von FAKIN aufgrund fehlender Personalresourcen (für die Erstellung standen 20 Personentage zur Verfügung) nicht möglich. Wie wichtig wäre es dir dass es einen solchen Wissensspeicher für das KWB gibt?

```{r, echo= FALSE}
w2 <- read.csv2("res_w2.csv")

is_unkown <- w2$Antwort == "Keine Ahnung"
wichtig <- w2[w2$Antwort == "Wichtig", ]
sehr_wichtig <- w2[w2$Antwort == "Sehr wichtig", ]
wichtig_sehrwichtig <- colSums(w2[!is_unkown, c("n", "percent")])
keine_ahnung <- w2[is_unkown, ]
```

Die Schaffung eines KWB Wissensspeichers wird von **`r round(wichtig_sehrwichtig[2],0)` Prozent** der Teilnehmer als **`r wichtig$Antwort`** (`r round(wichtig$percent,0)` Prozent) oder sogar **`r sehr_wichtig$Antwort`** (`r round(sehr_wichtig$percent,0)` Prozent) eingestuft (Tab. 5).

Die `r keine_ahnung$n` Teilnehmer (`r keine_ahnung$percent` Prozent) die mit 
**`r keine_ahnung$Antwort`** antworteten, sind vermutlich der knapp bemessenen 
Bearbeitungszeit geschuldet. Dadurch war es Einzelnen nicht möglich sich mit der 
Thematik in der ausreichenden Tiefe auseinander zu setzen (vgl. Kommentare von 
user_id = 24 in Tab. 5/6, sowie user_id = 21 in Tab. 7).

*Tab. 5: Bedarfsanalyse: KWB Wissensspeicher (Frage 9)*
```{r, echo= FALSE, results='as.is'}
sel_w2 <- w2[,c("Antwort", "n", "percent")]

names(sel_w2) <- c("", "Anzahl", "Prozent")
knitr::kable(sel_w2)
```

*Tab. 6: Kommentare zu Bedarf KWB Wissensspeicher*
```{r, echo= FALSE, results='as.is'}
comments_w2 <- comments[grepl(pattern = "^W2", comments$question_id), ] 

knitr::kable(comments_w2)
```

### Wunschliste

**Frage:** Welche Frage die der [FAKIN Wissensspeicher](../../) noch nicht beantwortet 
sollte dir ein KWB Wissensspeicher beantworten? Welche Datenquelle müsste dazu 
angezapft werden?

*Tab. 7: Wünsche an KWB Wissensspeicher (Frage 10)*

```{r, echo= FALSE, results='as.is'}
comments_w3 <- comments[grepl(pattern = "^W3", comments$question_id), ] 

knitr::kable(comments_w3)
```